---
phase: 02-data-collection
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/collectors/types.ts
  - src/filters/bots.ts
  - src/filters/emails.ts
  - src/parsers/date.ts
  - src/parsers/pagination.ts
  - src/collectors/commits.ts
autonomous: true

must_haves:
  truths:
    - "Contributor data structure captures all activity types (commits, PRs, issues)"
    - "Bot accounts are filtered from results"
    - "Generic email domains are excluded from email capture"
    - "Date filtering works for 12-month default window"
    - "Commit authors are extracted with pagination support"
  artifacts:
    - path: "src/collectors/types.ts"
      provides: "ContributorActivity, Collector interface, CollectorResult"
      exports: ["ContributorActivity", "Collector", "CollectorResult"]
    - path: "src/filters/bots.ts"
      provides: "Bot detection for GitHub usernames"
      exports: ["isBot", "BOT_PATTERNS"]
    - path: "src/filters/emails.ts"
      provides: "Generic email domain filtering"
      exports: ["isGenericEmail", "GENERIC_DOMAINS"]
    - path: "src/parsers/date.ts"
      provides: "Date parsing and comparison utilities"
      exports: ["isWithinWindow", "getDefaultSince", "parseGitHubDate"]
    - path: "src/parsers/pagination.ts"
      provides: "Extract next page URLs from GitHub HTML"
      exports: ["extractNextPage", "extractCursorPagination"]
    - path: "src/collectors/commits.ts"
      provides: "Commit author extraction with cursor pagination"
      exports: ["CommitCollector"]
  key_links:
    - from: "src/collectors/commits.ts"
      to: "src/collectors/types.ts"
      via: "implements Collector interface"
      pattern: "implements Collector"
    - from: "src/collectors/commits.ts"
      to: "src/parsers/pagination.ts"
      via: "cursor pagination extraction"
      pattern: "extractCursorPagination"
    - from: "src/collectors/commits.ts"
      to: "src/filters/bots.ts"
      via: "filters bot accounts"
      pattern: "isBot"
---

<objective>
Create the data collection foundation: TypeScript interfaces, utility modules for filtering and date handling, and the first collector (commits) with cursor-based pagination.

Purpose: Establish the type system and patterns that all collectors will follow, plus implement commit extraction as the first vertical slice.
Output: Working commit collector that can paginate through all commits in a repository.
</objective>

<execution_context>
@/Users/jesse/.claude/get-shit-done/workflows/execute-plan.md
@/Users/jesse/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-data-collection/02-CONTEXT.md
@.planning/phases/02-data-collection/02-RESEARCH.md
@src/types/index.ts
@src/scraper/client.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create collector types and filter utilities</name>
  <files>
    src/collectors/types.ts
    src/filters/bots.ts
    src/filters/emails.ts
    src/parsers/date.ts
  </files>
  <action>
Install dependencies first:
```bash
npm install cheerio date-fns
```

Create `src/collectors/types.ts`:
- ContributorActivity interface with fields: username, commits, prsAuthored, prsReviewed, issuesAuthored, issuesCommented, emails (Set<string>), lastActivityDate (Date), profileFetched (boolean)
- CollectorResult interface: contributors (Map<string, ContributorActivity>), nextPage (string | null), itemsProcessed (number)
- Collector interface: collectPage(url: string): Promise<CollectorResult>, getStartUrl(owner: string, repo: string, since?: Date): string
- createEmptyActivity(username: string): ContributorActivity helper function
- mergeContributors(existing: Map, incoming: Map): Map helper function

Create `src/filters/bots.ts`:
- BOT_PATTERNS array with: /\[bot\]$/i, /^dependabot$/i, /^renovate$/i, /^renovate-bot$/i, /^greenkeeper$/i, /^snyk-bot$/i, /^semantic-release-bot$/i, /^github-actions$/i, /^mergify$/i, /^codecov$/i, /^allcontributors$/i, /^imgbot$/i, /^stale$/i
- isBot(username: string): boolean function that tests against all patterns

Create `src/filters/emails.ts`:
- GENERIC_DOMAINS Set with: gmail.com, googlemail.com, yahoo.com, yahoo.co.uk, ymail.com, hotmail.com, hotmail.co.uk, outlook.com, live.com, msn.com, aol.com, icloud.com, me.com, mac.com, protonmail.com, proton.me, mail.com, email.com, zoho.com, yandex.com, yandex.ru, mail.ru, fastmail.com, fastmail.fm, tutanota.com, tutamail.com, users.noreply.github.com
- isGenericEmail(email: string): boolean that extracts domain and checks Set membership

Create `src/parsers/date.ts`:
- Import parseISO, isAfter, subMonths from date-fns
- parseGitHubDate(dateStr: string): Date - wraps parseISO for consistent handling
- isWithinWindow(date: Date, since: Date): boolean - returns isAfter(date, since)
- getDefaultSince(): Date - returns subMonths(new Date(), 12)
  </action>
  <verify>
```bash
npm run build
```
Build succeeds without errors.
  </verify>
  <done>
All type definitions and utility functions exist with proper TypeScript exports. Utilities are pure functions ready for use by collectors.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create pagination parser</name>
  <files>
    src/parsers/pagination.ts
  </files>
  <action>
Create `src/parsers/pagination.ts`:
- Import cheerio (use `import * as cheerio from 'cheerio'`)
- extractCursorPagination($: cheerio.CheerioAPI): string | null
  - Look for "Older" link: $('a[rel="nofollow"]').filter((_, el) => $(el).text().includes('Older')).attr('href')
  - If found, return full URL (prepend https://github.com if relative)
  - Return null if no more pages
- extractPagePagination($: cheerio.CheerioAPI): string | null
  - Look for next page link: $('a.next_page').attr('href') OR $('a[rel="next"]').attr('href')
  - If found, return full URL
  - Return null if no more pages
- extractNextPage($: cheerio.CheerioAPI, type: 'commits' | 'issues' | 'prs'): string | null
  - Delegates to extractCursorPagination for commits
  - Delegates to extractPagePagination for issues/prs

Note: GitHub's HTML may have changed since research. The selectors above are best guesses. If they don't work during verification, inspect the actual HTML and update selectors accordingly.
  </action>
  <verify>
```bash
npm run build
```
Build succeeds. Pagination module exports all three functions.
  </verify>
  <done>
Pagination extraction handles both cursor-based (commits) and page-based (issues/PRs) patterns.
  </done>
</task>

<task type="auto">
  <name>Task 3: Create commit collector with pagination</name>
  <files>
    src/collectors/commits.ts
  </files>
  <action>
Create `src/collectors/commits.ts`:
- Import cheerio, GitHubClient, types, filters, parsers
- CommitCollector class implementing Collector interface
- Constructor takes GitHubClient instance
- getStartUrl(owner: string, repo: string, since?: Date): string
  - Returns `https://github.com/${owner}/${repo}/commits`
  - Note: Time filtering will be done client-side (GitHub commits URL doesn't support date filtering directly)
- collectPage(url: string, since?: Date): Promise<CollectorResult>
  - Fetch HTML via client.fetch(url)
  - Load into cheerio: const $ = cheerio.load(html)
  - Parse commits: Find commit elements (try selectors like 'div[data-testid="commit-row"]' or '.TimelineItem' or similar - inspect GitHub HTML)
  - For each commit:
    - Extract username from user link (a[data-hovercard-type="user"])
    - Extract date from relative-time element's datetime attribute
    - If since provided and date < since, skip (strict cutoff)
    - If isBot(username), skip
    - Add to contributors map with commits++ count
  - Extract nextPage using extractNextPage($, 'commits')
  - If we hit a commit older than since, set nextPage to null (stop pagination)
  - Return { contributors, nextPage, itemsProcessed }

Error handling: If selector doesn't match expected structure, log warning in verbose mode but don't throw. Return empty result so collection can continue.

Key insight: GitHub's commit page structure may vary. Add defensive checks and fallback selectors. The collector should gracefully handle missing data rather than crashing.
  </action>
  <verify>
```bash
npm run build
```
Build succeeds.

Manual verification (will be done during execution):
- Executor should test against a small repo like https://github.com/sindresorhus/is to verify commit extraction works
- Check that pagination finds "Older" link correctly
  </verify>
  <done>
CommitCollector extracts usernames from commit pages, handles cursor pagination with "Older" links, filters bots, and respects time boundaries.
  </done>
</task>

</tasks>

<verification>
After all tasks complete:
1. `npm run build` succeeds
2. All new files exist: src/collectors/types.ts, src/filters/bots.ts, src/filters/emails.ts, src/parsers/date.ts, src/parsers/pagination.ts, src/collectors/commits.ts
3. TypeScript types are properly exported
4. date-fns and cheerio are in package.json dependencies
</verification>

<success_criteria>
- ContributorActivity type captures all activity metrics per user
- Bot filtering excludes known bot accounts
- Email filtering excludes generic domains
- Date utilities handle GitHub's ISO timestamps
- CommitCollector implements Collector interface
- Cursor pagination extracts next page from "Older" link
- Time-based cutoff stops pagination when reaching old commits
</success_criteria>

<output>
After completion, create `.planning/phases/02-data-collection/02-01-SUMMARY.md`
</output>
